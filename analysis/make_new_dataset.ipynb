{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f8d1424-a6f0-435b-a964-2547a5f24b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import h5py\n",
    "# Load the image\n",
    "import sys\n",
    "import numpy\n",
    "numpy.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "\n",
    "def find_hsv_puck(image, hsv_low=[0,0,0], hsv_high=[255, 255, 255], hsv_alt=None):\n",
    "    # hsv_alt should e a lit\n",
    "    h, w, _ = image.shape\n",
    "    \n",
    "    # Convert the left half of the image to HSV\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "    # We'll lower the saturation and value thresholds to possibly capture a darker green\n",
    "    refined_lower = np.array(hsv_low)  # Lower saturation and value\n",
    "    refined_upper = np.array(hsv_high)\n",
    "    # print(hsv_image[:,:,2])\n",
    "    # Create a mask for green color in the left half with the refined thresholds\n",
    "    refined_mask = cv2.inRange(hsv_image, refined_lower, refined_upper)\n",
    "    remove_table_edges_mask = np.zeros((h,w), dtype=np.uint8)\n",
    "    remove_table_edges_mask[0:175, 30:290] = 1\n",
    "    # remove_table_edges_mask[, :] = 1\n",
    "    # refined_mask *= remove_table_edges_mask\n",
    "    refined_mask[320:,:] = 0\n",
    "    puck_idx = np.where(refined_mask)\n",
    "    refined_result = cv2.bitwise_and(image, image, mask=refined_mask)\n",
    "    \n",
    "    return cv2.cvtColor(refined_result,cv2.COLOR_HSV2RGB), puck_idx, np.stack([refined_mask,refined_mask,refined_mask]).transpose(1,2,0)\n",
    "\n",
    "\n",
    "def load_hdf5_to_dict(datapath):\n",
    "    \"\"\"\n",
    "    Load a hdf5 dataset into a dictionary.\n",
    "\n",
    "    :param datapath: Path to the hdf5 file.\n",
    "    :return: Dictionary with the dataset contents.\n",
    "    \"\"\"\n",
    "    data_dict = {}\n",
    "    \n",
    "    # Open the hdf5 file\n",
    "    with h5py.File(datapath, 'r') as hdf:\n",
    "        # Loop through groups and datasets\n",
    "        def recursively_save_dict_contents_to_group(h5file, current_dict):\n",
    "            \"\"\"\n",
    "            Recursively traverse the hdf5 file to save all contents to a Python dictionary.\n",
    "            \"\"\"\n",
    "            for key, item in h5file.items():\n",
    "                if isinstance(item, h5py.Dataset):  # if it's a dataset\n",
    "                    current_dict[key] = item[()]  # load the dataset into the dictionary\n",
    "                elif isinstance(item, h5py.Group):  # if it's a group (which can contain other groups or datasets)\n",
    "                    current_dict[key] = {}\n",
    "                    recursively_save_dict_contents_to_group(item, current_dict[key])\n",
    "\n",
    "        # Start the recursive function\n",
    "        recursively_save_dict_contents_to_group(hdf, data_dict)\n",
    "\n",
    "    return data_dict\n",
    "\n",
    "\n",
    "mousepos = (0,0,1)\n",
    "Mimg = np.load('../Mimg.npy')\n",
    "\n",
    "upscale_constant = 3\n",
    "original_size = np.array([640, 480])\n",
    "visual_downscale_constant = 1/2\n",
    "save_downscale_constant = 1\n",
    "offset_constants = np.array((2100, 500))\n",
    "\n",
    "\n",
    "def homography_transform(image, get_save=True):\n",
    "    # image = cv2.rotate(image, cv2.ROTATE_180)\n",
    "    save_image = None\n",
    "    if get_save:\n",
    "        save_image = cv2.resize(image, (int(640/save_downscale_constant), int(480/save_downscale_constant)))\n",
    "    image = cv2.resize(image, (int(640*upscale_constant), int(480*upscale_constant)), \n",
    "                interpolation = cv2.INTER_LINEAR)\n",
    "    dst = cv2.warpPerspective(image,Mimg,original_size * upscale_constant)\n",
    "    dst = cv2.rotate(dst, cv2.ROTATE_90_CLOCKWISE)\n",
    "    showdst = cv2.resize(dst, (int(480*upscale_constant / visual_downscale_constant), int(640*upscale_constant / visual_downscale_constant)), \n",
    "                interpolation = cv2.INTER_LINEAR)\n",
    "    return showdst, save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c51a29-657f-432e-b5aa-503d59f8d98f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/mrudolph/miniconda3/envs/airhockey/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/u/mrudolph/miniconda3/envs/airhockey/lib/python3.11/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 147.5, 148.0, 147.0, 146.0, 145.0, 143.0, 143.0, 141.0, 140.0, 139.5, 139.0, 139.0, 140.0, 140.0, 140.0, 140.0, 140.0, 140.0, 140.0, 139.0, 139.0, 138.0, 137.0, 131.0, 129.0, 131.0, 132.0, 132.0, 132.0, 132.0, 132.0, 133.0, 132.0, 132.5, 133.0, 132.0, 133.0, 132.0, 133.0, 133.0, 133.0, 133.0, 133.0, 133.0, 133.0, 133.0, 133.0, 133.0, 133.0, 132.0, 133.0, 133.0, 133.0, 133.0, 133.0, 133.0, 133.0, 133.0, 133.0, 132.0, nan, 120.0, 95.0, 79.0, 48.0, 34.0, 48.0, 75.0, 84.5, nan, nan, nan, nan, 76.0, 68.0, 51.0, 42.0, 34.5, 42.0, 48.0, 65.0, 72.0, 87.0, 95.0, 110.0, 115.0, 123.0, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]\n",
      "[194.0, 194.0, 194.0, 194.0, 194.0, 194.0, 194.0, 194.0, 194.0, 194.0, 196.0, 197.0, 199.0, 201.5, 203.0, 206.0, 206.0, 209.0, 209.0, 208.0, 207.0, 207.0, 208.0, 209.0, 210.0, 210.0, 210.0, 210.0, 213.0, 216.0, 221.0, 221.0, 223.0, 222.5, 222.0, 220.0, 218.0, 214.0, 210.0, 202.0, 197.0, 196.0, 196.0, 199.0, 200.0, 199.0, 199.0, 199.0, 200.0, 200.0, 201.0, 202.0, 202.0, 202.0, 201.0, 198.0, 192.0, 191.0, 190.0, 189.0, 189.0, 188.0, 192.0, 202.0, 200.0, 174.0, 170.0, 159.0, 154.0, 144.0, 140.0, 131.0, 125.0, 120.0, 111.0, 102.0, 98.0, 88.0, 84.0, 75.0, 71.0, 68.0, 68.0, 194.0, 81.0, 86.0, 94.0, 99.0, 192.0, 112.0, 119.0, 123.5, 190.0, 189.0, 187.5, 187.0, 186.0, 186.0, 186.0, 186.0, 185.0, 183.5, 184.0, 187.0, 189.0, 193.0, 194.0, 195.0, 196.0, 196.0, 198.0, 198.0, 200.0, 199.0, 200.0, 200.0, 201.0, 203.0, 206.0, 206.0, 285.0, 285.0, 281.0, 275.0, 272.0, 266.0, 263.0, 258.0, 253.0, 206.0, 202.0, 201.0, 201.0, 201.0, 204.0, 205.0, 223.0, 218.0, 201.0, 200.0, 200.0, 199.5, 199.0, 198.0, 197.0, 194.0, 190.0, 188.0, nan, 175.0, 172.0, 162.0, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 97.0, 98.0, 112.0, 118.0, 126.0, 128.0, 130.0, 131.0, 131.0, 134.0, 133.0, 138.0, 136.0, nan, 137.0, nan, 137.0, 136.5, 138.0, 134.0, 127.0, 117.0, nan, nan, 46.0, 32.0, 6.0, 16.0, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]\n",
      "[153.0, 153.0, 153.0, 153.0, 153.0, 153.0, 153.0, 153.0, 153.0, 154.0, 153.0, 153.0, 153.0, 153.0, 153.0, 153.0, 154.0, 155.0, 156.0, 158.0, 161.0, 166.0, 164.0, 163.0, 159.0, 145.0, 142.0, 142.0, 143.0, 143.0, 142.0, 141.0, 141.0, 140.0, 139.0, 140.0, 139.0, 139.0, 139.0, 138.0, 138.0, 137.0, 138.0, 135.0, 135.0, 132.0, 133.0, 132.0, 132.0, 131.0, 129.0, 162.5, 163.0, 163.0, 84.0, 73.0, 50.0, 50.0, 72.0, 82.0, 93.0, 113.0, 123.0, 143.0, 153.0, 166.0, 175.0, 193.0, 202.0, 166.0, 167.0, 167.0, 257.0, 267.0, 286.0, 284.0, 267.0, 258.0, 242.5, 234.0, 218.0, 209.0, 193.0, 186.0, 177.0, 162.0, 158.0, 141.0, 132.0, 114.0, 105.0, 86.0, 77.0, 59.0, 52.0, 52.0, 156.0, 161.0, 161.0, 161.0, 104.0, 107.0, 121.0, 129.0, 146.0, 153.0, 161.0, 161.0, 161.0, 161.0, 162.0, 162.0, 161.0, 162.0, 162.0, 162.0, 162.0, 162.0, 162.0, 161.0, 162.0, 161.0, 159.0, 155.0, 155.0, nan, 144.0, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]\n"
     ]
    }
   ],
   "source": [
    "for traj in range(200,300):\n",
    "    try:\n",
    "        path = f'/datastor1/calebc/public/data/mouse/trajectories/trajectory_data{traj}.hdf5'\n",
    "        dataset_dict = load_hdf5_to_dict(path)\n",
    "        xs,ys = [], []\n",
    "        for img in dataset_dict['train_img']:\n",
    "            # train_img = dataset_dict['train_img'][120]\n",
    "            train_img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "            \n",
    "            dst, img = homography_transform(train_img)\n",
    "            refined_img, idx,mask = find_hsv_puck(img, [0,100,100], [50,255,255])\n",
    "            x,y = np.median(idx[0]), np.median(idx[1])\n",
    "            xs.append(x)\n",
    "            ys.append(y)\n",
    "            xy_pixel = np.array([xs,ys])\n",
    "        np.save(f'/datastor1/calebc/public/data/mouse/trajectories/state_trajectories/state_trajectory_data{traj}.hdf5', xy_pixel)\n",
    "        print(xs)\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c55e02-74b7-4bfe-b576-2407ba27ac63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
